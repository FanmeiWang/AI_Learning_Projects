# AI Learning Projects
**An exploration of AI concepts and techniques through coursework, assignments, and practical coding exercises.**

## Overview
This repository is a collection of AI-focused projects and exercises that I completed as part of my studies in Artificial Intelligence. The projects here cover a range of topics, including data preprocessing, machine learning models, and natural language processing. Each project demonstrates foundational skills and aims to build a strong understanding of AI principles.

**Note:** Variable names, dataset names, and specific details have been anonymized to protect original coursework content.

## Contents
1. **Data Preprocessing and Cleaning**: Basic techniques for handling missing data, data normalization, and feature engineering.
2. **Machine Learning Models**: Implementations of foundational supervised and unsupervised machine learning algorithms. Includes clustering (e.g., K-Means), classification (e.g., Logistic Regression, Decision Tree), and dimensionality reduction (e.g., PCA, LDA)..

## Installation & Dependencies
To run the notebooks in this repository, you will need Python 3 and the following packages:

**Core Libraries** <br>
'numpy' - For numerical computations. <br>
'pandas' - For data manipulation and analysis. <br>
'scikit-learn' - For implementing machine learning models, clustering, and dimensionality reduction. <br>
'matplotlib' - For creating visualizations. <br>
'seaborn' - For enhanced data visualization. <br>

Install these packages using pip: 

```bash
pip install numpy pandas scikit-learn matplotlib seaborn nltk
```

## Usage
1. Clone the repository to your local machine:
```bash
git clone https://github.com/FanmeiWang/AI_Learning_Projects.git
```
2. Navigate to the repository folder:
```bash
cd AI_Learning_Projects
```
3. Open any of the Jupyter notebooks to start exploring the projects.

## File Structure
Here's an overview of the mail files and folders in this repository:
```
AI_Learning_Projects/
├── Data_Cleaning/                      # Preprocessing raw data
│   └── data_cleaning.ipynb             # Includes handling missing values, normalization, and type conversion
├── Exploratory_Data_Analysis/          # Understanding data structure
│   └── exploratory_analysis.ipynb      # Visualizations and data distribution analysis
├── Feature_Engineering/                # Enhancing model input
│   └── feature_engineering.ipynb       # Creating new features, selecting relevant ones
├── Supervised_Learning/                # Tasks with labeled data
│   ├── classification_models.ipynb     # Logistic Regression, Decision Tree, Random Forest, Naive Bayes
│   ├── lda_analysis.ipynb              # Dimensionality reduction for classification tasks
├── Unsupervised_Learning/              # Discovering patterns without labels
│   ├── kmeans_clustering.ipynb         # K-Means clustering with Manhattan distance
│   ├── pca_analysis.ipynb              # Principal Component Analysis for dimensionality reduction
├── README.md                           # Overview of the repository
└── requirements.txt                    # List of dependencies

```

---

## Important Note on Intellectual Property

In order to protect the intellectual property associated with this project, all variable names and dataset identifiers have been replaced with generic placeholders (e.g., `VAR1`, `VAR2`, `data.csv`). These changes do not affect the code's logic but remove any proprietary information. The code remains functional and demonstrates the workflow and logic behind typical AI tasks.

## Contents

1. **Data Loading** - Demonstrates how data files are imported.
2. **Data Cleaning** - Illustrates methods for handling missing data using generic variable names.
3. **Exploratory Data Analysis** - Provides visualizations and statistical summaries.
4. **Feature Engineering** - Shows techniques for creating and selecting meaningful features.

---

## Important Note on Intellectual Property

In order to protect the intellectual property associated with this project, all variable names and dataset identifiers have been replaced with generic placeholders (e.g., `VAR1`, `VAR2`, `data.csv`). These changes do not affect the code's logic but remove any proprietary information. 

---





{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyCczWoJv9a/Me9Iy3CiV3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FanmeiWang/AI_Learning_Projects/blob/main/Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP778vJPXYC2"
      },
      "outputs": [],
      "source": [
        "# feature_engineering.ipynb\n",
        "# Auto-generated module: feature_engineering.ipynb\n",
        "# Contains code extracted from the notebook\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import chi2, mutual_info_regression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load data (assuming generic file \"data.csv\")\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Select only numerical columns for correlation calculation\n",
        "df_num = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Compute the correlation matrix\n",
        "correlation = df_num.corr()\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(\"Correlation Matrix:\\n\", correlation)\n",
        "\n",
        "# Extract the features with the highest correlation with target variable VAR1\n",
        "if 'VAR1' in correlation.columns:\n",
        "    print(\"Correlation with VAR1:\\n\", correlation['VAR1'])\n",
        "else:\n",
        "    print(\"'VAR1' column not found in the correlation matrix\")\n",
        "\n",
        "# Preparing data for chi-square and mutual information\n",
        "X = df.drop(columns=['VAR1'])  # Drop target variable (assumed as VAR1)\n",
        "y = df['VAR1']  # Define target variable as VAR1\n",
        "\n",
        "# Convert categorical columns to numerical values\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "# Discretize numerical features to prepare for chi-square test\n",
        "for col in X.select_dtypes(include=['float64', 'int64']).columns:\n",
        "    X[col] = X[col].fillna(X[col].median())  # Fill missing values with median\n",
        "    X[col] = pd.cut(X[col], bins=5, labels=False)  # Discretize into 5 bins\n",
        "\n",
        "# Chi-square feature selection\n",
        "chi_scores, p_values = chi2(X, y)\n",
        "chi_square_results = pd.DataFrame({\"Feature\": X.columns, \"Chi-square score\": chi_scores, \"p_value\": p_values})\n",
        "print(chi_square_results)\n",
        "\n",
        "# Mutual Information feature selection\n",
        "mutual_info = mutual_info_regression(X, y)\n",
        "mutual_info_results = pd.Series(mutual_info, index=X.columns)\n",
        "print(\"Mutual Information Scores:\\n\", mutual_info_results.sort_values(ascending=False))\n",
        "\n",
        "# Random Forest Feature Importances\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X, y)\n",
        "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "print(\"Random Forest Feature Importances:\\n\", feature_importances.sort_values(ascending=False))\n"
      ]
    }
  ]
}